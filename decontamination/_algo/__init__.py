# -*- coding: utf-8 -*-
########################################################################################################################

import typing

import numpy as np
import numba.cuda as cu

from .. import jit

########################################################################################################################
# DATASET UTILITIES                                                                                                    #
########################################################################################################################

def dataset_to_generator_builder(dataset: typing.Union[np.ndarray, typing.Callable]) -> typing.Callable:

    return dataset if callable(dataset) else lambda: lambda: (dataset, )

########################################################################################################################

def batch_iterator(vectors: np.ndarray, n_chunks: int) -> typing.Iterator[np.ndarray]:

    ####################################################################################################################

    chunk_size, chunk_remaining = divmod(vectors.shape[0], n_chunks)

    ####################################################################################################################

    for i in range(n_chunks):

        s = i * chunk_size
        e = s + chunk_size

        yield vectors[s: e]

    ####################################################################################################################

    if chunk_remaining > 0:

        yield vectors[n_chunks * chunk_size:]

########################################################################################################################
# CPU & GPU> UTILITIES                                                                                                 #
########################################################################################################################

@jit(parallel = False)
def add_scalar_xpu(dest: np.ndarray, src: float) -> None:

    ####################################################################################################################
    # !--BEGIN-CPU--

    dest += src

    # !--END-CPU--
    ####################################################################################################################
    # !--BEGIN-GPU--

    for i in range(dest.shape[0]):

        cu.atomic.add(dest, i, src)

    # !--END-GPU--

########################################################################################################################

@jit(parallel = False)
def add_vector_xpu(dest: np.ndarray, src: np.ndarray) -> None:

    ####################################################################################################################
    # !--BEGIN-CPU--

    dest += src

    # !--END-CPU--
    ####################################################################################################################
    # !--BEGIN-GPU--

    for i in range(dest.shape[0]):

        cu.atomic.add(dest, i, src[i])

    # !--END-GPU--

########################################################################################################################

@jit(parallel = False)
def square_distance_xpu(vector1: np.ndarray, vector2: np.ndarray) -> float:

    ####################################################################################################################
    # !--BEGIN-CPU--

    return np.sum((vector1 - vector2) ** 2)

    # !--END-CPU--
    ####################################################################################################################
    # !--BEGIN-GPU--

    result = 0.0

    for i in range(vector1.shape[0]):

        result += (vector1[i] - vector2[i]) ** 2

    return result

    # !--END-GPU--
########################################################################################################################
